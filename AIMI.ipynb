{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from skimage.io import imread\n",
    "from skimage.io import imshow\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import resize\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as tc\n",
    "# tc.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import Mednet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image\n",
    "# Citation : Case courtesy of A.Prof Frank Gaillard, Radiopaedia.org, rID: 33753\n",
    "path = \"~/Documents/SCU/workshops/AIMI/alzheimer-disease-ct-only.png\"\n",
    "img = imread(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display image\n",
    "imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looks like the original image has 4 channels\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I am going to arbitrarily select one channel\n",
    "# Note : Do not select the last channel\n",
    "img_ch = img[:,:,0]\n",
    "# 1 channel image\n",
    "img_ch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "imshow(img_ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize image\n",
    "# img_ch = normalize(img_ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I resized to (96, 96) because I trained the network on (96, 96) images\n",
    "shape = (96, 96)\n",
    "img_ch = resize(img_ch, shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity Check\n",
    "# Well, we squished the brain, but it is still recognizable as a brain\n",
    "# Would it be better to crop the image? Perhaps, select a (96, 96) portion of the image?\n",
    "plt.imshow(img_ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_ch = tc.Tensor(img_ch).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_ch = tc.unsqueeze(img_ch, dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_ch = tc.unsqueeze(img_ch, dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity Check\n",
    "img_ch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we are ready to pass the image into the network!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####\n",
    "# Load the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "model = Mednet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the model that we are using.\n",
    "# repr(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model weights\n",
    "path = \"pretrained_weights.pth\"\n",
    "model.load_state_dict(tc.load(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####\n",
    "# Unfortunately, I cannot redistribute the dataset to train and test the network.\n",
    "####\n",
    "\n",
    "# TPR = Sensitivity\n",
    "# Sensitivity = Recall = TP/(TP + FN) = (# guessed positive and correct)/(# actually positive) = How many positive cases you caught\n",
    "# If Recall is low, FN is high and a lot of positive cases slipped through the cracks\n",
    "\n",
    "# FPR = 1 - Specificity\n",
    "# Specificity TN/(TN + FP) = (# guessed negative and correctly)/(# actually negative) = How many negative cases you caught\n",
    "# FPR = FP/(TN + FP) = (# guess positive and incorrectly)/(# actually negative)\n",
    "# FPR = 1 - How many negative cases you caught = How many negative cases slipped through the cracks\n",
    "\n",
    "# TP : Guessed P and were right\n",
    "# TN : Guessed N and were right\n",
    "# FP : Guessed P and were wrong\n",
    "# FN : Guessed N and were wrong\n",
    "\n",
    "# ROC Curve\n",
    "# TPR = How many positive case you caught\n",
    "# FPR = How many negative cases fell through the cracks\n",
    "# Ideally, TPR = 1, meaning you caught all positive cases and have no FN!!!\n",
    "# & FPR = 0, meaning none of the negative cases slipped through the cracks!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class Activation Mapping (CAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract layer names and weights\n",
    "keys = list(model.state_dict().keys())\n",
    "values = list(model.state_dict().values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(keys[len(keys) - 1])\n",
    "print(keys[-1], values[-1])\n",
    "# Class 0 weight\n",
    "# Class 1 weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w0 = values[-1][0]\n",
    "w1 = values[-1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(w0, w1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract feature maps from last convolutional layer\n",
    "probs, features = model(img_ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results in a CAM for each class\n",
    "# Each CAM allows us to see what features contribute to the class prediction\n",
    "CAM0 = tc.zeros(features.shape[2], features.shape[3])\n",
    "CAM1 = tc.zeros(features.shape[2], features.shape[3])\n",
    "\n",
    "idx = 0 # a specific sample in the batch\n",
    "for i in range(features.shape[1]):\n",
    "    CAM0 += features[idx][i]*w0\n",
    "    CAM1 += features[idx][i]*w1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize Class Activation Maps if the network downsamples the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(CAM0.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(CAM1.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
